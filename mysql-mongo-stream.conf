env {
  # You can set flink configuration here
  execution.parallelism = 2
  job.mode = "STREAMING"
  #job.mode = "BATCH"
  checkpoint.interval = 2000
  #execution.checkpoint.interval = 10000
  #execution.checkpoint.data-uri = "hdfs://localhost:9000/checkpoint"
}

source {

  MySQL-CDC {
    result_table_name = "fake"
    server-id = 5656
    username = "gaian"
    password = "gaian"
    table-names = ["ps.content_info4"]
    base-url = "jdbc:mysql://localhost:3306/ps"
    startup.mode ="LATEST"
  }
}

transform {
  Sql {
  result_table_name="fake2"
  source_table_name = "fake"
   query = "SELECT CONCAT(SUBSTRING(RAWTOHEX(id),1,8),'-',SUBSTRING(RAWTOHEX(id),9,4),'-',SUBSTRING(RAWTOHEX(id),13,4),'-',SUBSTRING(RAWTOHEX(id),17,4),'-',SUBSTRING(RAWTOHEX(id),21)) AS uuid_id, created_by, created_date, last_modified_by, last_modified_date, content_length, content_type, description, file_extension, file_name, file_path, hls_request_id, hls_status, hls_url, is_encrypted, md5_check_sum, meta_data, service_id, tenant_id, user_id FROM fake;"
  }
}

sink {
  mongodb {
    uri = "mongodb://127.0.0.1:27017/ps?retryWrites=true&writeConcern=majority"
    database = "ps"
    collection = "content_info5"
  }

}
