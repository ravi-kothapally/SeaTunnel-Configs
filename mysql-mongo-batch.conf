env {
  # You can set flink configuration here
  execution.parallelism = 2
  job.mode = "BATCH"
  checkpoint.interval = 2000
  #execution.checkpoint.interval = 10000
  #execution.checkpoint.data-uri = "hdfs://localhost:9000/checkpoint"
}

source {

  Jdbc {
        result_table_name="gaian"
        url = "jdbc:mysql://localhost:3306/content_service"
        driver = "com.mysql.cj.jdbc.Driver"
        connection_check_timeout_sec = 100
        user = "gaian"
        password = "gaian"
        query = "SELECT LOWER(INSERT(INSERT(INSERT(INSERT(HEX(id), 9, 0, '-'), 14, 0, '-'), 19, 0, '-'), 24, 0, '-')) AS id, created_by, created_date, last_modified_by, last_modified_date,  content_type, description, file_extension, file_name, file_path, hls_request_id, hls_status, hls_url, service_id, tenant_id, user_id FROM content_info"
    }
}

sink {

  Elasticsearch {
    source_table_name="gaian"
    hosts = ["localhost:9200"]
    username = ""
    password = ""
    index = "content_info"
    # cdc required options
    primary_keys = ["id"]
  }
}
